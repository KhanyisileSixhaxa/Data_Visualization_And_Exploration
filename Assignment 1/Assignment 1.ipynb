{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Introduction to Data Visualization and Exploration\n",
    "# Assignment 1\n",
    "\n",
    "## Group Members:\n",
    "#### Khanyisile Sixhaxa: 1590202\n",
    "#### Tsireledzo Ravelle: 1821249\n",
    "#### Keletso Pule:\n",
    "#### Charlotte Savage: 1079415"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1.1.1 Data cleaning and outliers\n",
    "\n",
    "There is a popular dataset (it is an older dataset but it checks out) that contains information on glass identification. There are 214 glass samples split amongst seven class categories and nine features, including\n",
    "the refractive index and the content in percent of eight elements: Na, Mg, Al, Si, K, Ca, Ba, and Fe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "import math\n",
    "sns.set_theme(style=\"white\")\n",
    "import scipy.cluster.hierarchy as shc\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Attribute Information\n",
    "1. Id number: 1 to 214\n",
    "2. RI: refractive index\n",
    "3. Na: Sodium (unit measurement: weight percent in corresponding oxide, as are attributes 4-10)\n",
    "4. Mg: Magnesium\n",
    "5. Al: Aluminum\n",
    "6. Si: Silicon\n",
    "7. K: Potassium\n",
    "8. Ca: Calcium\n",
    "9. Ba: Barium\n",
    "10. Fe: Iron\n",
    "11. Type of glass: (class attribute)\n",
    "  - 1: building_windows_float_processed\n",
    "  - 2: building_windows_non_float_processed\n",
    "  - 3: vehicle_windows_float_processed\n",
    "  - 4: vehicle_windows_non_float_processed (none in this database)\n",
    "  - 5: containers\n",
    "  - 6: tableware\n",
    "  - 7: headlamps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "columns= ['Id', 'RI', 'Na', 'Mg', 'Al', 'Si', 'K', 'Ca', 'Ba', 'Fe', 'GlassType']\n",
    "df = pd.read_csv('glass.data', names=columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "scrolled": true
   },
   "source": [
    "#### 1. Using visualisations, explore the feature variables to understand their distributions as well as the relationships between predictors. Here, include histograms, bar charts, correlation heatmaps, etc."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Get the total number of each glass type\n",
    "print(\"GlassType   Total\")\n",
    "df['GlassType'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.style.use(\"seaborn\")\n",
    "fig, ax =plt.subplots(figsize=(8,6))\n",
    "sns.countplot(x = df[\"GlassType\"]);\n",
    "plt.title(\"Glass Types Distribution\",fontsize=15, y=1.03);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.style.use(\"seaborn\")\n",
    "fig, ax = plt.subplots(figsize=(10,8))\n",
    "\n",
    "plt.pie(x=df[\"GlassType\"].value_counts(), \n",
    "        labels=[\"Glass Type 2\", \"Glass Type 1\", \"Glass Type 7\", \"Glass Type 3\", \"Glass Type 5\", \"Glass Type 6\"],\n",
    "        shadow = True, \n",
    "        autopct=\"%1.2f%%\", \n",
    "        )\n",
    "plt.title(\"Glass Types Distribution Pie Chart\",fontsize=15)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Letâ€™s plot the distribution of each feature\n",
    "def plot_distribution(dataset, cols=5, width=20, height=15, hspace=0.2, wspace=0.5):\n",
    "    plt.style.use('seaborn-whitegrid')\n",
    "    fig = plt.figure(figsize=(width,height))\n",
    "    fig.subplots_adjust(left=None, bottom=None, right=None, top=None, wspace=wspace, hspace=hspace)\n",
    "    rows = math.ceil(float(dataset.shape[1]) / cols)\n",
    "    for i, column in enumerate(dataset.columns):\n",
    "        ax = fig.add_subplot(rows, cols, i + 1)\n",
    "        ax.set_title(column)\n",
    "        if dataset.dtypes[column] == np.object:\n",
    "            g = sns.countplot(y=column, data=dataset)\n",
    "            substrings = [s.get_text()[:18] for s in g.get_yticklabels()]\n",
    "            g.set(yticklabels=substrings)\n",
    "            plt.xticks(rotation=25)\n",
    "        else:\n",
    "            g = sns.distplot(dataset[column])\n",
    "            plt.xticks(rotation=25)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cols_to_plot = ['RI', 'Na', 'Mg', 'Al', 'Si', 'K', 'Ca', 'Ba', 'Fe', 'GlassType']\n",
    "plot_distribution(df[cols_to_plot], cols=3, width=20, height=20, hspace=0.45, wspace=0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.pairplot(df[['RI', 'Na', 'Mg', 'Al', 'Si', 'K', 'Ca', 'Ba', 'Fe', 'GlassType']],hue='GlassType')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "features = ['RI','Na','Mg','Al','Si','K','Ca','Ba','Fe']\n",
    "label = ['GlassType']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(15,15))\n",
    "sns.heatmap(df.corr(),annot = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Above diagrams shows that our dataset is skewed either on positive or negative side, and the data is not normalized. The heatmap diagram shows that refractive index (RI) and Calcium (Ca) have the strongest correlation between them, Aluminum (Al) and Barium (Ba) have intermediate correlation between them , and, Magnesium (Mg) and Barium (Ba) have the weakest correlation between them. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2. Can you find any outliers? Are any of the distributions of the features skewed?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "for column in df:\n",
    "    plt.figure()\n",
    "    df.boxplot([column], vert = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see from the box and whisker diagrams that in the Iron (Fe), Barium (Ba), Calcium (Ca), Pottasium (K), Silicon (Si), Aluminum (Al), Sodium (Na) and Refractive index (RI) columns there are a lot of outliers. Furthermore, the Magnesium (Mg) column does not show any oulier(s). Above diagrams shows that our dataset is skewed either on positive or negative side, and the data is not normalized.\n",
    "1. refractive index (RI):  Right-skewed distribution (Positive)\n",
    "2. Sodium (Na): Right-skewed distribution (Positive)\n",
    "3. Magnesium (Mg): Left-skewed distribution (Negative)\n",
    "4. Aluminum (Al): Right-skewed distribution (Positive)\n",
    "5. Silicon (Si): Left-skewed distribution (Negative)\n",
    "6. Potassium (K): Left-skewed distribution (Negative)\n",
    "7. Calcium (Ca): Right-skewed distribution (Positive)\n",
    "8. Barium (Ba): Right-skewed distribution (Positive)\n",
    "9. Iron (Fe): Right-skewed distribution (Positive)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3. What types of transformations of one (or more) of these features might improve the classification model?\n",
    "\n",
    "Normalization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1.1.2 Data cleaning and missing values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1.1.3 Feature Selection and Engineering"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1.1.4 Dimensionality Reduction\n",
    "Use the penguin dataset for this section. For this piece do not worry about cleaning the data or looking for missing values.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pip install palmerpenguins"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import seaborn as sns \n",
    "from palmerpenguins import load_penguins\n",
    "sns.set_style('whitegrid')\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "penguin = load_penguins()\n",
    "penguins= penguin.replace( {'Adelie':0 , 'Gentoo':1, 'Chinstrap':2,'Torgersen':0, 'Dream': 1,'Biscoe':2, 'female':0,'male':1} )\n",
    "penguins = penguins.fillna(0);\n",
    "penguins.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "penguins_data = penguins[['island','bill_length_mm','bill_depth_mm','flipper_length_mm','body_mass_g','sex','year']]\n",
    "penguins_target = penguins.species"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1. Perform PCA with 2 and then 4 components. Show the explained variance for the different PCs.\n",
    "\n",
    "#### PCA with 2 components"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.decomposition import PCA\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import pandas as pd\n",
    "scaler = StandardScaler()\n",
    "\n",
    "pca2 = PCA(n_components=2)\n",
    "x_pca2 = pca2.fit_transform(scaler.fit_transform(penguins_data))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### PCA with 4 components"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pca4 = PCA(n_components=4)\n",
    "# raw data\n",
    "x_pca4_raw = pca4.fit_transform(penguins_data)\n",
    "\n",
    "# standardised data \n",
    "x_pca4_std = pca4.fit_transform(scaler.fit_transform(penguins_data))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Explained Variance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "def plot_cumul_var(pcamodel):\n",
    "    plt.bar(range(1,len(pcamodel.explained_variance_ )+1),pcamodel.explained_variance_ )\n",
    "    plt.ylabel('Explained variance')\n",
    "    plt.xlabel('Components')\n",
    "    plt.plot(range(1,len(pcamodel.explained_variance_ )+1),\n",
    "             np.cumsum(pcamodel.explained_variance_),\n",
    "             c='red',\n",
    "             label=\"Cumulative Explained Variance\")\n",
    "    plt.legend(loc='upper left')\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "def plot_expl_var_ratio(pcamodel):\n",
    "    plt.plot(pcamodel.explained_variance_ratio_)\n",
    "    plt.xlabel('number of components')\n",
    "    plt.ylabel('cumulative explained variance')\n",
    "    plt.show()\n",
    "\n",
    "#PCA1 is at 0 in xscale\n",
    "\n",
    "def plot_expl_variance(pcamodel):\n",
    "    plt.plot(pcamodel.explained_variance_)\n",
    "    plt.xlabel('number of components')\n",
    "    plt.ylabel('cumulative explained variance')\n",
    "    plt.show()\n",
    "\n",
    "def plot_heatmap(pcamodel, columns):\n",
    "    ax = sns.heatmap(pcamodel.components_,\n",
    "                     cmap='YlGnBu',\n",
    "                     yticklabels=[ \"PCA\"+str(x) for x in range(1,pcamodel.n_components_+1)],\n",
    "                     xticklabels=columns,\n",
    "                     cbar_kws={\"orientation\": \"horizontal\"})\n",
    "    ax.set_aspect(\"equal\")\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### (i) Explained variance for PCA with 2 compnents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot variance ratio\n",
    "plot_expl_var_ratio(pca2)\n",
    "# plot a heatmap showing which variables are contributing to each PC\n",
    "plot_heatmap(pca2, list(['island','bill_length_mm','bill_depth_mm','flipper_length_mm','body_mass_g','sex','year']))\n",
    "print('Total Variance Captured by Principle Components: {0}%'.format(pca2.explained_variance_ratio_.sum()*100.))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### (ii) Explained Variance for PCA with 4 components "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot variance ratio\n",
    "plot_expl_var_ratio(pca4)\n",
    "# plot a heatmap showing which variables are contributing to each PC\n",
    "plot_heatmap(pca4, list(['island','bill_length_mm','bill_depth_mm','flipper_length_mm','body_mass_g','sex','year']))\n",
    "print('Total Variance Captured by Principle Components: {0}%'.format(pca4.explained_variance_ratio_.sum()*100.))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2. Then, for the PCA with 4 components, make a scatterplot for the first two principle components for a) the raw data and b) standardised data. What do you notice about these different plots?\n",
    "\n",
    "#### Scatterplot of the first two principle components using the raw data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.scatter(x_pca4_raw[:, 0], x_pca4_raw[:, 1], c=penguins.species, alpha=0.8, marker='o')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Sactterplot of the first two principle components using the standardised data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.scatter(x_pca4_std[:, 0], x_pca4_std[:, 1], c=penguins.species, alpha=0.8, marker='o')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### What do you notice about these different plots?\n",
    "From the scatterplot of the raw data, we can see that we were not able to reduce 8 features into 4 features whereas for the standardised data the 8 features were reduced to 4."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
